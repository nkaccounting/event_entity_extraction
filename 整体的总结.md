##做了一下数据的统计信息：

C Q的长度，Q的种类和数量

##分层抽样

然后基于原始的带answer的train.csv，采用了按照Q类型进行分层抽样的方法，划分出来了训练集和验证集（原本的eval没有本地的答案）

##训练

经过了几轮的训练，稍微有一点点心得

这个金融事件主体抽取的上游任务是事件侦测，相当于做文本分类，分类出21种类型+其他

“其他”对应的answer都是no answer

直接放进去训练以后

Inference的时候发现，无论是什么情况，只要遇到“其他”，直接输出no answer
而不管句子里有没有某个Q的事件类型都会抽取出东西

我理解模型学到了两个东西：

其他->必然匹配no answer

每个Q都有answer，模型也不知道什么时候给no answer

然后事件类型统一都是发生某种负面消息的公司，模型不管Q是什么，都输出发生某种负面消息的公司

评测结果为：

    {
        "exact": 87.99102132435466,
        "f1": 90.715851918643,
        "total": 1782,
        "HasAns exact": 85.42234332425068,
        "HasAns f1": 88.73000553066876,
        "HasAns total": 1468,
        "NoAns exact": 100.0,
        "NoAns fl": 100.0,
        "NoAns total": 314
}

##no answer的改进

我觉得这个no answer学出来没有意义，还不如定义一个规则，过滤Q为“其他”的数据

于是就把其他的数据删除，然后在生成（C，Q，A）的时候，按照正常的（C，Q，A）+（C，Q1，no answer）放进模型里面进行训练；Q1是从所有问题类型中随机采样一个不同于原本Q的问题类型

这样做，总的has answer和no answer是1:1

但是对于每个Q的类型，has answer和no answer要看原本的数量和随机情况

（可能可以按每种Q都是1:1的方法来优化
潜在的问题随机的Q可能有答案，但较少情况会出现）
这样训练下来，模型可以对不包含的事件类型，输出no answer了

评测结果为：

    {
        "exact": 91.79155313351498,
        "fl": 93.21976089884444,
        "total": 2936,
        "HasAns exact": 86.78474114441417,
        "HasAns f": 89.641156675073,
        "HasAns total": 1468,
        "NoAns exact": 96.7983651226158,
        "NoAns fl": 96.7983651226158,
        "NoAns total": 1468
}

##做了一下wrong analysis：

对于预测不准的数据，感觉模型倾向于抽取靠近clue近的实体，还有就是基于训练的answer长度，1-4长度的居多，模型也会倾向于抽取出短实体）

一个感觉就是MRC实际上没有真正理解语言，一些有两个公司比较，有对抗的情况，就会表现不好

##最后inference了几条网上找的数据

随机query查询

    QAInput('高管负面', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'), 云联惠公司，正确抽取
    QAInput('我爱你', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'),空，正确抽取
    QAInput('业绩下滑', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'), 空，正确抽取
    QAInput('蜜雪冰城甜蜜蜜', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'), 空，正确抽取
    QAInput('营收爆增', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'), 空，正确抽取
    QAInput('北京大学', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'), 云联惠公司（？？？不知道为啥了）
    QAInput('高管正面', '今年6月，经检察机关批准，广州警方以涉嫌组织、领导传销活动罪对云联惠公司实际控制人黄某等主要犯罪嫌疑人执行逮捕'), 云联惠公司（学习的泛化性，把营收上涨和下滑视作同一类，不会区别）

面对一个新的query，感觉模型算出来应该是这个Q和之前训练过的哪个query比较相近，也就是说，在这种训练下（营收暴增=营收下跌），（高管正面=高管负面）

本来是打算做一个主动学习的，用eval，这个不带答案的数据作为未标注数据，采用最大score比较小的这些样例，手动标注
然后再训练
但是比较多的score值较低的情况是涉及到“多实体”都涉及某种事件的情况
少部分0.56是属于就是我们说的模棱两可的情况
